# SailoGrowth Workflow Backend

Complete backend implementation for the workflow automation system.

## ðŸ—ï¸ Architecture

```
User Interface (React Flow)
         â†“
  API Routes (Next.js)
         â†“
  Service Layer
    â”œâ”€ OpenRouter Service (LLM)
    â”œâ”€ Data Connector (Supabase/PostHog/etc)
    â”œâ”€ Action Executor (Slack/Email/Webhook)
    â””â”€ Workflow Executor (Orchestration)
```

## ðŸ“ Project Structure

```
lib/
â”œâ”€â”€ types/
â”‚   â””â”€â”€ workflow.ts              # TypeScript type definitions
â””â”€â”€ services/
    â”œâ”€â”€ openrouter.ts            # LLM integration (OpenRouter)
    â”œâ”€â”€ data-connector.ts        # Database connections
    â”œâ”€â”€ action-executor.ts       # Notifications & actions
    â””â”€â”€ workflow-executor.ts     # Workflow orchestration

app/api/workflow/
â”œâ”€â”€ interpret-schema/
â”‚   â””â”€â”€ route.ts                 # POST: Analyze schema with LLM
â”œâ”€â”€ test-connection/
â”‚   â””â”€â”€ route.ts                 # POST: Test data source connection
â”œâ”€â”€ test-action/
â”‚   â””â”€â”€ route.ts                 # POST: Test notification/action
â”œâ”€â”€ generate-query/
â”‚   â””â”€â”€ route.ts                 # POST: Generate monitoring query
â””â”€â”€ execute/
    â””â”€â”€ route.ts                 # POST: Execute complete workflow
```

## ðŸ”‘ Environment Setup

Create `.env.local` in project root:

```bash
# OpenRouter API (REQUIRED)
OPENROUTER_API_KEY=sk-or-v1-your-actual-key-here

# Optional: App metadata
OPENROUTER_APP_NAME=SailoGrowth
OPENROUTER_APP_URL=http://localhost:3001
```

## ðŸš€ API Endpoints

### 1. Test Connection
**POST** `/api/workflow/test-connection`

Tests connectivity to a data source.

```json
{
  "connectionConfig": {
    "type": "supabase",
    "endpoint": "https://xyz.supabase.co",
    "apiKey": "your-api-key",
    "database": "postgres"
  }
}
```

**Response:**
```json
{
  "success": true,
  "message": "Successfully connected to Supabase",
  "connectionTime": 234
}
```

---

### 2. Interpret Schema
**POST** `/api/workflow/interpret-schema`

Fetches schema from data source and uses LLM to interpret it.

```json
{
  "connectionConfig": {
    "type": "supabase",
    "endpoint": "https://xyz.supabase.co",
    "apiKey": "your-api-key"
  },
  "model": "anthropic/claude-3-sonnet",
  "temperature": 0.7
}
```

**Response:**
```json
{
  "success": true,
  "schema": {
    "tables": [...],
    "relationships": [...],
    "entities": [...]
  },
  "interpretation": "The database contains user events, sessions...",
  "model": "anthropic/claude-3-sonnet"
}
```

---

### 3. Generate Monitoring Query
**POST** `/api/workflow/generate-query`

Generates SQL query for monitoring using LLM.

```json
{
  "entityDescription": "User events table with signup and login events",
  "condition": "New user signups exceed 100 per day",
  "model": "anthropic/claude-3-sonnet"
}
```

**Response:**
```json
{
  "success": true,
  "query": "SELECT COUNT(*) FROM events WHERE event_type = 'signup' AND created_at >= NOW() - INTERVAL '1 day'",
  "explanation": "Counts signup events in the last 24 hours",
  "model": "anthropic/claude-3-sonnet"
}
```

---

### 4. Test Action
**POST** `/api/workflow/test-action`

Tests notification/action delivery.

```json
{
  "actionConfig": {
    "type": "slack",
    "slackWebhook": "https://hooks.slack.com/services/...",
    "message": "ðŸš¨ Alert: {{condition}} detected at {{timestamp}}"
  }
}
```

**Response:**
```json
{
  "success": true,
  "message": "Slack notification sent successfully",
  "timestamp": "2025-10-27T23:00:00.000Z"
}
```

---

### 5. Execute Workflow
**POST** `/api/workflow/execute`

Executes a complete workflow from start to finish.

```json
{
  "workflowId": "workflow-123",
  "nodes": [
    {
      "id": "data-connector-1",
      "type": "data-connector",
      "data": {
        "label": "Data Connector",
        "config": {
          "connectionType": "supabase",
          "endpoint": "https://xyz.supabase.co",
          "apiKey": "key",
          "database": "postgres"
        }
      }
    },
    {
      "id": "schema-interpreter-1",
      "type": "schema-interpreter",
      "data": {
        "label": "Schema Interpreter",
        "config": {
          "model": "anthropic/claude-3-sonnet",
          "temperature": 0.7
        }
      }
    }
  ],
  "edges": [
    {
      "id": "e1-2",
      "source": "data-connector-1",
      "target": "schema-interpreter-1"
    }
  ]
}
```

**Response:**
```json
{
  "success": true,
  "execution": {
    "id": "exec-1698789123456",
    "status": "completed",
    "startedAt": "2025-10-27T23:00:00.000Z",
    "completedAt": "2025-10-27T23:00:15.000Z",
    "logs": [
      {
        "nodeId": "workflow",
        "timestamp": "2025-10-27T23:00:00.000Z",
        "level": "info",
        "message": "Workflow execution started"
      },
      {
        "nodeId": "data-connector-1",
        "timestamp": "2025-10-27T23:00:02.000Z",
        "level": "info",
        "message": "Connected to supabase, found 5 tables"
      }
    ]
  }
}
```

## ðŸ§© Service Layer

### OpenRouter Service
Handles all LLM interactions using OpenRouter API.

**Features:**
- Schema interpretation
- Query generation
- Alert message templating

**Models Supported:**
- `anthropic/claude-3-opus`
- `anthropic/claude-3-sonnet`
- `openai/gpt-4`
- `openai/gpt-3.5-turbo`

### Data Connector Service
Manages connections to various data sources.

**Supported:**
- âœ… Supabase (REST API)
- âœ… PostHog (REST API)
- ðŸš§ PostgreSQL (requires pg library)
- ðŸš§ MySQL (requires mysql2 library)
- ðŸš§ BigQuery (requires @google-cloud/bigquery)

### Action Executor Service
Executes notifications and webhooks.

**Supported:**
- âœ… Slack (webhook)
- ðŸš§ Email (needs SendGrid/SES integration)
- âœ… Custom Webhooks
- ðŸš§ HubSpot
- ðŸš§ Custom API calls

### Workflow Executor Service
Orchestrates the entire workflow execution.

**Features:**
- Topological sorting (correct execution order)
- Context passing between nodes
- Error handling and logging
- Execution state tracking

## ðŸ”§ Usage Examples

### Frontend Integration

```typescript
// Test connection
const testConnection = async (config: any) => {
  const response = await fetch('/api/workflow/test-connection', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ connectionConfig: config })
  })
  const result = await response.json()
  return result
}

// Interpret schema
const interpretSchema = async (config: any) => {
  const response = await fetch('/api/workflow/interpret-schema', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      connectionConfig: config,
      model: 'anthropic/claude-3-sonnet',
      temperature: 0.7
    })
  })
  const result = await response.json()
  return result
}

// Execute workflow
const executeWorkflow = async (nodes: any[], edges: any[]) => {
  const response = await fetch('/api/workflow/execute', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      workflowId: 'workflow-' + Date.now(),
      nodes,
      edges
    })
  })
  const result = await response.json()
  return result
}
```

## ðŸ”’ Security

- API keys are stored server-side only
- No `NEXT_PUBLIC_` prefix for sensitive keys
- User-provided API keys are validated
- Rate limiting recommended for production
- Add authentication middleware for API routes

## ðŸ“Š Next Steps

1. **Add to NodeDetailsPanel:**
   - Wire up "Test Connection" button â†’ API call
   - Wire up "Save Configuration" button â†’ update node config
   - Show real-time feedback from API

2. **Add Cron Job Scheduling:**
   - Use Vercel Cron or similar
   - Schedule monitor executions
   - Store results in database

3. **Add Database:**
   - Store workflow configurations
   - Store execution history
   - Store monitor results

4. **Add Authentication:**
   - Protect API routes
   - Multi-tenant support
   - API key management

5. **Add Email Integration:**
   - SendGrid or AWS SES
   - Email templates
   - Delivery tracking

## âœ… What Works Now

- âœ… OpenRouter LLM integration
- âœ… Supabase connection testing
- âœ… PostHog connection testing
- âœ… Schema interpretation with Claude
- âœ… Monitoring query generation
- âœ… Slack notifications
- âœ… Webhook triggers
- âœ… Complete workflow execution
- âœ… Execution logging

## ðŸš€ Ready to Use!

The backend is fully functional. You can now:
1. Connect to Supabase or PostHog
2. Interpret schemas with AI
3. Generate monitoring queries
4. Send Slack/webhook alerts
5. Execute complete workflows

Start testing with the API endpoints!
